# [1] Deployement
### 배포 종류 3가지 : 블루- 그린, 롤링(default), 카나리 배포.
1. 블루-그린: 구조가 간단하며 관리가 편함. 신버전으로 label만 바꿔주면 됨. but 서비스가 일시적으로 중단될 수 있음. 
2. 롤링 : 점진적으로 변경. maxSurge를 1로 했을때 replica가 3이면 1개를 더 유지 할 수 있다. 그러면 1개를 신규버전으로 넣음. maxUnavailable: 0 Replicas=3 
   **maxSurge**=1(레플리카 개수보다 1개 더 올라갈 수 있다) 
   **maxUnavailable**=0(레플리카 개수보다 뺄수있다) 
   구조복잡. 버전이 혼합되어있어. 버전 차이에 인한 이슈발생가능.
3. 카나리 배포: 처음에 new버전을 label을 blue를 해두고, 시간이 지나면서 new버전의 개수를 늘리고 네트워크 트래픽이 바꿔도 문제 없는지 확인 후 전부 전환한다(오프라인 타임을 가지지 않는다)

```jsx
#kubectl rollout history : 개정정보 확인하기
#kubectl rollout undo : 마지막으로 했던 update를 취소
#kubectl rollout undo [deployment 이름] --to-revision=1 : 특정 버전의 개정번호로 롤백
#kubectl rollout pause: Update 일시 중지 (카나리 배포처럼 쓸때 사용하기도함 많이X)
#kubectl rollout status: 현재 상태 확인
#kubectl replace : 새버전의 Deployment로 전체 Deployment를 교체
#kubectl patch 또는 #kubectl edit : 새버전의 새컨테이너 이미지 삽입
#kubectl set image : Deployment에 새 이미지 삽입
#kubectl apply -f 파일명 --record  : 개정 이력에 명령어를 기록해 히스토리에서 확인할 수 있다.
```

- 디플로이먼트 올라가면 rs컨트롤러가 같이 올라감. rs명은 디플로이언트명-해쉬값으로 붙임. 
	  파드명: 디플로이언트명-XXX(해쉬값)-YYY(해쉬값)
- Annotation : 이미지 정보, 필드, 디버깅 시 필요

```jsx
annotations:
    kubernetes.io/change-cause: "test rolling update version 1:1"  #내용추가하기
```

- minReadySeconds
   pod가 running을 하더라도 백그라운드에서 준비시간이 있을수가 있는데 ready가 될때 까지 delaytime이 있음. 
	   레디니스 프로브: Ready상태인지 체크(포트 체크, var/Ready체크) → Ready상태 → endpoint 리소스 생성 → 클라이언트가 네트워크를 통해서 연결할 수 있다. → N/W 트래픽 가능.
    - **minReadySeconds**: Ready가 되어있어도 바로 롤링 업데이트를 진행하지 않고 기다려주는 시간(잘못된 프로그램인지 체크하기 위한 여유시간이라 봐도 됨, Ready를 유지하는 시간) → 효과: **롤링 업데이트 간격조절의 효과**로 사용할 수 있다.
    - setimage옵션을 사용하여 새컨테이너 이미지 배포 
      kubectl set image deployment test1 test1="이미지이름"
- 잘못된경우 rollback
	kubectl rollout undo deployment test1 #바로전_업데이트
    kubectl rollout undo deployment test1 --to-revision=1 #revision_개정_이력_롤백
    - kubectl get all -o wide를 해서 해당하는 replicaset Controller가 어떤이미지로 정보를 수집해서 알 수 있다. running 중인 애는 desired 숫자가 높은 애가 replicaset Control이다.
- 레디니스 프로브와 minReadySeconds 구성

```jsx
apiVersion: apps/v1
kind: Deployment
metadata:
  name: test1
spec:
  replicas: 3
  minReadySeconds: 10   #설정하기
strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0 #디플로이먼트가 파드를 하나씩 교체하도록 maxUnavailable을 0으로 설정
    type: RollingUpdate
  selector:
    matchLabels:
      app: test1
  template:
    metadata:
      name: test1
      labels:
        app: test1
    spec:
      containers:
      - image:${이미지이름} #이 이미지는 에러가 발생하도록 만들어진 샘플
        name: test1
        readinessProbe:
          periodSeconds: 1      # 매초마다 실행될 레디니스 프로브를 정의한다.
          httpGet:      #레디니스 프로브는 컨테이너에 HTTP GET요청을 수행한다.
            path: /
            port: 8080
```
- **readiness probe**: 엔드포인트 리소스 등록 허가. 
	  체크 메커니즘 3가지: (exec, http get, tcp소켓) 프로브 - 포트, 경로
	  ls /var/ready: 참(0), 거짓(0이 아닌값)으로 shell이 판단
	  echo $?: 방금전 실행한 shell이 결과를 보여주는 값
	  내부 container에 명령어로 ready파일 생성: kubectl exec test1-56f6ccfbfb-8chpf -- touch /var/ready
	  레디니스 프로브는 주기적으로 파일을 점검 한다(따라서 파일을 지우면 종료됨)
    
    - k exec test1-6dcf78bcc8-l5f4p -- rm -rf /var/ready
    
    delay time(default 0) : 그 즉시에 체크 됨(중요)
    
- liveness probe: 동작원리는 같음. 컨테이너가 살아 있는지 확인할 수 있다.
    
- **minReadySeconds설정 이해하기** 
	   initialDelaySeconds: 120   
	   120초지나야 조건이 맞더라도 ready가된다. 게임 사이트의 경우 롤링 업데이트 많이사용. 은행권은 블루그린 많이(점검 시간)
	- initialDelaySeconds: 240, minReadySeconds: 360 
	  240초 지나고 ready가 되고 360초 지나고 나면 롤링업데이트가 올라간다
### blue green 배포

오프라인타임 잠시 발생 할 수 있음. 그린이라는 label을 바꿔주면 변경되는데. 서비스 파일 하나가지고 조작하는 것보다, 각각 yaml파일을 가지고 있는게 좋다. 서비스 네임이 같으면 configure돼서 수정된다. 네트워크 트래픽이 그린으로 변경되지만, 블루가 남아있어 하드웨어 리소스를 잡아먹는다. 
kubectl patch service test-svc -p “$(cat green-test-svc.yaml)”
 ”$()”: 명령어 대체. 특수문자 차단 단순히 문자화. **쿼팅 문자**라 함. 
### 카나리 배포 
- replicas의 비중이 중요하다. 비율은 수동으로 조절.
