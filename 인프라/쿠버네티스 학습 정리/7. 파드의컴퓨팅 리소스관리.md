# [1] 파드의 컴퓨팅 리소스 관리
1. 컨테이너의 CPU, 메모리 컴퓨팅 리소스 요청
2. CPU와 메모리에 대한 엄격한 제한 설정
3. 네임스페이스에서 파드의 기본, 최소, 최대 리소스 설정
4. 네임스페이스에서 사용 가능한 리소스의 총량 제한.

## 1] 파드 컨테이너의 리소스 요청
- 파드을 생성할 때 컨테이너가 필요로 하는 cpu와 메모리 사용량 제한
- 파드의 리소스 요청(requests)와 제한(limits)은 모든 컨테이너 리소스 요청과 제한의 합
- 메트릭서버: system metric을 수집하는 Mertics-server 배포 필요. 
	- #kubectl top 명령어로 모니터링
	- 리소스 메트릭을 수집하고 HPA(Horizontal Pod AutoScaler) 및 VPA(Vertical Pod AutoScaler)에서 사용할 수 있도록 Metrics API를 통해 Kubernetes apiserver에 노출
		- HPA: cpu/mem 기반 수평 자동 확장, VPA: 컨테이너에 필요한 리소스 자동 조정/제안
	- Metrics Server는 자동 확장 이외의 용도로 사용되지 않음. 모니터링 솔루션은 Prometheus 같은 소스 활용(메트릭은 장시간 저장하지 않기때문)
	- 각 노드의 Kubelet에 cpu와 메모리 사용을 질의. 
		- kubelet에 cAdvisor라는에이전트가 있어 노드에서 실행되는 개별 컨테이너와 노드전체의 리소스 사용데이터를 수집.
		- 전체 클러스터에 있는 cAdvisor로부터 데이터를 수집해 한곳에 노출시킨다
		- 통계 데이터 저장을 위해 InfluxDB사용, 시각적 분석을 위해 Grafana 사용
	- [Metrics Server Github](https://github.com/kubernetes-sigs/metrics-server/releases)
	
## 2] 컨테이너를 위한 리소스 요청과 제한을 갖는 파드
1. 리소스 요청(requests)은 파드에 필요한 리소스의 최소량을 지정
2. 워커 노드는 파드에 할당 가능한 cpu와 memory가 충족할경우에만 파드 스케줄링. 즉 최소 요청(request)을 만족하는 노드에 파드 스케줄링.
3. 컨테이너에 대한 limit을 지정하면, kubelet은 실행중인 컨테이너가 설정한 제한보다 많은 리소스를 사용할 수 없도록 제한.
4. 컨테이너가 사용한 실제 리소스 사용량에 기반하지 않고 리소스 요청량(request)의 전체합 만을 본다(그래야 이미 배포된 파드들의 실행에 영향을 미치지 않기 때문)
	- 단위: cpu 1m(밀리코어, 1000m이 1 물리 코어), memory: 1Mi(Mebi Btyes)
	
## 3] 스케줄러가 파드를 위해 최적의 노드를 선택할 때 파드의 요청을 사용하는 방법
1. 요청된 리소스양에 기반해 노드의 우선순위를 정함(실제 사용된 리소스의야은 고려X)
2. LeastRequestedPriority: 할당되지않은 리소스의 양이 큰 노드 선호
	- 리소스 부하를 노드에 고르게 분산(돈이 많이 든다)
3. MostRequestedPriority: 요청된 리소스가 많은 노드 선호
	- 적은 수의 노드를 사용 보장. 특정노드를 비울 수있고 제거할 수 있다.
	- 노드의 용량 검사: capacity는 노드의 총 리소스를 나타냄. 스케줄러는 오직 allocatable 리소스 양을 기준으로 설정
	
## 4] 컨테이너가 사용 가능한 리소스 양을 엄격한 제한(limit)으로 설정
1. cpu, memory의 사용할 수 있는 최대량을 제한
2. 리소스에 제한을 지정하여 다른 파드 스케줄링에 악영향을 미치지 않도록 함
	- 프로세스가 제한보다 많은 메모리 할당 시도하면 프로세스 종료 OOM(Out of Memory)
	- Restart Policy가 Always or OnFailure인 경우 다시 시작하며, 지속 종료되면 CrashLoopBackoff 상태로 표시
- reuqest를 설정하지 않고 limit을설정하면 requset = limit, QOS class: Guaranteed 자동 설정

- 컨테이너는 노드의 모든 cpu를 본다(cpu제한을 1코어로 해도 컨테이너에 cpu 1코어만을 노출 X)
- ex) 64코어 cpu에 실행중인 1코어 cpu제한의 컨테이너는 한개코어에서만 실행되는것이 아닌 cpu시간의 1/64을 가지고 있으므로 다른 시점에서 다른코어에서 코드가 실행될 수 있음

## 5] 파드에 대한 서비스 품질(QoS) 구성
- 서비스 품질(QoS) 클래스를 할당하기 위해 어떻게 파드를 구성해야 하는지 결정
- 쿠버네티스는 QOS 클래스를 사용하여 파드 스케줄링과 축출 결정
### 1) 파드 QOS 클래스
- 리소스 제한은 overcommit될 수 있음. 노드가 모든 파드의 리소스 제한에서 지정한 양만큼만 리소스를 제공할 거라 생각하면 안됨.
- 쿠버네스에서 드의 우선순위를 지정하는 방법 3가지 서비스 품질(QOS)클래스로 분류
	- BestEffort(최하위 우선순위), Burstable, Guaranteed(최상위 우선순위)

### 2) 메모리가 부족할 떄 어떤 프로세스가 종료되는지
- BestEffot클래스가 -> Burstable 파드 -> Guaranteed파드는 시스템 프로세스가 메모리를 필요로 하는경우에만 종료
- 동일한 QOS를 갖는 컨테이너는 메모리의 비율이 높은 컨테이너를 종료

## 6] 네임스페이스에 대한 기본 메모리, cpu Request, limit 구성
### 1) limit Range 리소스 사용 (kind: LimitRange)
- 각 컨테이너에 리소스 요청과 제한 설정 대신 컨테이너의 각 리소스에(네임스페이스 별) 최소/최대 제한을 지정하고, 리소스 요청을 명시적으로 지정하지 않느 ㄴ컨테이너의 기본 리소스 요청을 지정한다.
- LimitRanger 어드미션 컨트롤 플러그인에서 사용
- LimitRange의 바람직한 사용: 클러스터의 어느 노드보다 큰 파드를 생성하려는 사용자를 막음
- 개별 파드에만 적용: 각파드가 최소, 최대값을 적용받는다. 많은 파드를 만들경우 클러스터에 사용가능한 모든 리소스를 써버리는 문제 발생 가능

## 7] 리소스쿼터 오브젝트 (kind: ResourceQuota)
- 네임스페이스에서 사용 가능한 총 리소스 양을 제할할 수 있는 방법
- 생성 중인 파드가 리소스쿼터를 초과하는 지호가인. 네임스페이스에서 파드가 사용할 수 있는 컴퓨티 리소스양과 PVC이 사용할 수 있는 스토리지 양을 제한.
- 스토리지제한, 생성가능한 오브젝트 수 제한(pod,rc,service,NodePort, publicIP...)
### 1) 노드 어피니티
- 노드 어피니티로 파드를 배포할 노드를 지정
```
affinity: 
        nodeAffinity:    	#노드어피니티 사용 선언
          requiredDuringSchedulingIgnoredDuringExecution: #노드어피니티 속성 이름
            nodeSelectorTerms:  # 노드에 파드를 스케줄링하기 위해 
            - matchExpressions:  # 노드의 레이블이 일치하도록 표현식으로 정의한다.
              - key: gpu
                operator: In
                values:
                - "true"
```
- hard affinity: requiredDuringSchedulingIgnoredDuringExecution, 파드가 노드에 스케줄 되도록 반드시 만족해야하는 규칙
- soft affinity: preferredDuringSchedulingIgnoredDuringExecution, 노드 우선순위(선호도)
- 연산자: In, NotIn, Exists, DoesNotExist

### 2) 파드 어피니티와 안티-어피니티
- 노드에서 실행중인 **파드 레이블 기반으로 파드가 스케줄 될 수 있는 노드를 제한한다
- 파드간 어피니티와 안티-어피니티에는 상당한 양의 프로세싱이 필요(수백 개의 노드를 넘어가는 클러스터에서 추천하지 않음)
- hard: requiredDuringSchedulingIgnoredDuringExecution
- soft: preferredDuringSchedulingIgnoredDuringExecution
- 파드 안티-어피니티(anti-affinity)
	- 파드를 서로 분산 배포(스케줄러는 podAntiAffinity의 레이블 셀렉터와 일치하는 파드가 실행 중인 노드를 선택하지 않음)
	- topologykey 속성은 파드를 배포해서는 안되는 범위를 결정.
